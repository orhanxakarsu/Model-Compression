{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87f152e-8ecb-44bd-8ec6-8ace30634301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a2f0f5-cdc7-4c58-ba0f-dc3384d3ba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Data Transformer\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,),(0.5,))])\n",
    "\n",
    "# 2 Create Train Dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train =True,\n",
    "                                    download = True, transform = transform)\n",
    "trainloader = DataLoader(trainset, batch_size =64, shuffle =True)\n",
    "\n",
    "#3 Create Test Dataset\n",
    "testset = torchvision.datasets.MNIST(root = \"./data\", train = False,\n",
    "                                     download = True, transform = transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a30cfd4e-b43a-4440-b236-23ce9214fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de6e79f3-8f45-4d06-8801-18aadcf20b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28,1028)\n",
    "        self.fc2 = nn.Linear(1028,256)\n",
    "        self.fc3 = nn.Linear(256,10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd247142-388e-436b-b299-dcea3b511359",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr =0.001)\n",
    "criterion  = nn.CrossEntropyLoss().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8325cfd-12ba-4992-a527-5f3ef864fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, testloader, criterion, device):\n",
    "    model.eval()  # Modeli değerlendirme moduna al\n",
    "    test_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Grad hesaplamalarını kapatıyoruz çünkü test sırasında geri yayılım yapılmaz\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            X, y = data\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Doğruluğu hesapla\n",
    "            _, predicted = torch.max(y_pred, 1)\n",
    "            correct_predictions += (predicted == y).sum().item()\n",
    "            total_predictions += y.size(0)\n",
    "\n",
    "    # Ortalama kayıp ve doğruluğu hesapla\n",
    "    average_test_loss = test_loss / len(testloader)\n",
    "    test_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f'Test Loss: {average_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "    \n",
    "    return average_test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a13616-afe2-4df9-a39d-367f8b60b2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2847, Accuracy: 0.9117\n",
      "Epoch 2, Loss: 0.1305, Accuracy: 0.9597\n",
      "Epoch 3, Loss: 0.1004, Accuracy: 0.9689\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    epoch_loss =0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    #set to train mode\n",
    "    model.train()\n",
    "\n",
    "    #train for all batches of data\n",
    "    for data in trainloader:\n",
    "        X, y = data\n",
    "        X , y = X.to(device), y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        #Calculate accuracy\n",
    "        _, predicted = torch.max(y_pred,1)\n",
    "        correct_predictions += (predicted ==y).sum().item()\n",
    "        total_predictions += y.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    average_loss = epoch_loss / len(trainloader)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ac2bee4-688b-489a-92ca-ffcfba89661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21a3b294-4b08-4e88-8906-1aac48e762f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_21908\\4016724546.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pruning_model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=1028, bias=True)\n",
       "  (fc2): Linear(in_features=1028, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model nesnesini oluştur\n",
    "pruning_model = Network()\n",
    "\n",
    "# Ağırlıkları yükle\n",
    "pruning_model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "\n",
    "# Modeli değerlendirme moduna al\n",
    "pruning_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c735785f-2e8a-4839-9cd0-1494b11633de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0990, Test Accuracy: 0.9698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09899375607870567, 0.9698)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model.to(device), testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab15f4a4-be16-4c93-b429-f6981a3cd484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a prunin threshold (lambda)\n",
    "threshold = 0.02\n",
    "\n",
    "# Implement zero-pruning\n",
    "for name, param in pruning_model.named_parameters():\n",
    "    if \"weight\" in name:\n",
    "        param.data[param.data.abs()<threshold] =0.0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12912539-6bcf-4179-b006-72ae7e04345d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0939, Test Accuracy: 0.9716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09387334367960312, 0.9716)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(pruning_model.to(device), testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18ba2c2a-7276-47ac-b19f-765e6a4e7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_percentage(model):\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "    \n",
    "    # Modelin state_dict'ini döngü ile dolaş\n",
    "    for name, param in model.state_dict().items():\n",
    "        # Sadece ağırlıkları (weights) kontrol et\n",
    "        if 'weight' in name:\n",
    "            total_params += param.numel()  # Toplam parametre sayısını artır\n",
    "            zero_params += (param == 0).sum().item()  # Sıfır olan parametre sayısını artır\n",
    "    \n",
    "    # Sıfır olan ağırlıkların yüzdesini hesapla\n",
    "    zero_percentage = (zero_params / total_params) * 100 if total_params > 0 else 0\n",
    "    \n",
    "    print(f'Toplam Weight Parametre Sayısı: {total_params}')\n",
    "    print(f'Sıfır Olan Weight Parametre Sayısı: {zero_params}')\n",
    "    print(f'Sıfır Olan Weight Parametre Yüzdesi: {zero_percentage:.2f}%')\n",
    "\n",
    "    return zero_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cf335f5-ce2b-48d3-92e3-708d30daa95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam Weight Parametre Sayısı: 1071680\n",
      "Sıfır Olan Weight Parametre Sayısı: 0\n",
      "Sıfır Olan Weight Parametre Yüzdesi: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_zero_percentage(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b102777-0e7f-4ed6-a979-a3e470a44756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam Weight Parametre Sayısı: 1071680\n",
      "Sıfır Olan Weight Parametre Sayısı: 528283\n",
      "Sıfır Olan Weight Parametre Yüzdesi: 49.29%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.29484547626157"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_zero_percentage(pruning_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb76ce37-0ad0-4194-b7d2-0ecfea87f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pruning_model.state_dict(),\"pruning_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9608f902-f27d-4d58-9cd5-738bcaf9f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use scipy to sparse matrix\n",
    "import scipy.sparse as sp\n",
    "\n",
    "sparse_weights = []\n",
    "\n",
    "#Convert the pruned weights to a sparse matrix\n",
    "for name,param in pruning_model.named_parameters():\n",
    "    if \"weight\" in name:\n",
    "\n",
    "        np_weight = param.data.cpu().numpy()\n",
    "        sparse_weights.append(sp.csr_matrix(np_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f263d2ad-390f-4e60-8611-b0b2ce70821a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       " \twith 416541 stored elements and shape (1028, 784)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       " \twith 124963 stored elements and shape (256, 1028)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       " \twith 1893 stored elements and shape (10, 256)>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "348610ef-5bb8-4198-b1a0-d4a925cd4f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.088134765625\n"
     ]
    }
   ],
   "source": [
    "total_size = 0\n",
    "\n",
    "for name, param in pruning_model.named_parameters():\n",
    "\n",
    "    if \"weight\" in name:\n",
    "\n",
    "        tensor = param.data\n",
    "        total_size += tensor.element_size() * tensor.numel()\n",
    "\n",
    "tensor_size_mb = total_size/(1024**2)\n",
    "print(tensor_size_mb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3053e9f-f8b1-4835-bc54-31a84557532d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.072895050048828\n"
     ]
    }
   ],
   "source": [
    "total_size = 0\n",
    "for w in sparse_weights:\n",
    "    total_size +=w.data.nbytes\n",
    "\n",
    "#Convert to MBs\n",
    "csr_size_mb = total_size /(1024**2)\n",
    "print(csr_size_mb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "929de38f-0216-43b6-a5bf-7fae340760f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters saved as CSR format at: pruned_model_csr\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, save_npz\n",
    "\n",
    "def save_model_as_csr(model, file_path):\n",
    "    # Modelin parametrelerini al\n",
    "    state_dict = model.state_dict()\n",
    "    \n",
    "    # Her bir parametreyi CSR formatında sakla\n",
    "    csr_weights = {}\n",
    "\n",
    "    for name, param in state_dict.items():\n",
    "        if param.requires_grad:\n",
    "            # Parametreyi numpy dizisine çevir\n",
    "            dense_param = param.detach().numpy()\n",
    "            # CSR matrisine dönüştür\n",
    "            csr_param = csr_matrix(dense_param)\n",
    "            csr_weights[name] = csr_param\n",
    "\n",
    "    # CSR formatındaki parametreleri kaydet\n",
    "    for name, csr_param in csr_weights.items():\n",
    "        print\n",
    "        save_npz(f\"{file_path}_{name}.npz\", csr_param)\n",
    "\n",
    "    print(f\"Model parameters saved as CSR format at: {file_path}\")\n",
    "\n",
    "# Örnek kullanım\n",
    "save_model_as_csr(pruning_model, \"pruned_model_csr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0dcd4144-8fab-4efd-a61c-abd62a536173",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pruned_model_csr_fc1.weight.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 30\u001b[0m\n\u001b[0;32m     21\u001b[0m param_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc1.weight\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc1.bias\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc3.bias\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     28\u001b[0m ] \u001b[38;5;66;03m# Modeldeki tüm parametre isimlerini listele\u001b[39;00m\n\u001b[0;32m     29\u001b[0m new_model \u001b[38;5;241m=\u001b[39m Network()\n\u001b[1;32m---> 30\u001b[0m load_model_from_csr(new_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpruned_model_csr\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_names)\n",
      "Cell \u001b[1;32mIn[83], line 9\u001b[0m, in \u001b[0;36mload_model_from_csr\u001b[1;34m(model, file_path, param_names)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# CSR formatındaki parametreleri yükle\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m param_names:\n\u001b[1;32m----> 9\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m load_npz(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Dosya adını doğru ver\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# CSR formatındaki veriyi yoğun (dense) numpy dizisine dönüştür\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     dense_param \u001b[38;5;241m=\u001b[39m loaded\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml_flow\\Lib\\site-packages\\scipy\\sparse\\_matrix_io.py:134\u001b[0m, in \u001b[0;36mload_npz\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_npz\u001b[39m(file):\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Load a sparse array/matrix from a file using ``.npz`` format.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m    >>> sparse_array = sp.sparse.csr_array(tmp)\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39mload(file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mPICKLE_KWARGS) \u001b[38;5;28;01mas\u001b[39;00m loaded:\n\u001b[0;32m    135\u001b[0m         sparse_format \u001b[38;5;241m=\u001b[39m loaded\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sparse_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml_flow\\Lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28mopen\u001b[39m(os_fspath(file), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pruned_model_csr_fc1.weight.npz'"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import load_npz\n",
    "\n",
    "def load_model_from_csr(model, file_path, param_names):\n",
    "    # Boş bir state_dict oluştur\n",
    "    state_dict = {}\n",
    "\n",
    "    # CSR formatındaki parametreleri yükle\n",
    "    for name in param_names:\n",
    "        loaded = load_npz(f\"{file_path}_{name}.npz\")  # Dosya adını doğru ver\n",
    "        # CSR formatındaki veriyi yoğun (dense) numpy dizisine dönüştür\n",
    "        dense_param = loaded.toarray()\n",
    "\n",
    "        # Yoğun numpy dizisini torch tensörüne çevir ve modele aktar\n",
    "        state_dict[name] = torch.tensor(dense_param, dtype=torch.float32)\n",
    "\n",
    "    # Yüklenmiş state_dict'i modele aktar\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(\"Model parameters loaded from CSR format.\")\n",
    "\n",
    "# Örnek kullanım\n",
    "param_names = [\n",
    "    'fc1.weight',\n",
    "    'fc1.bias',\n",
    "    'fc2.weight',\n",
    "    'fc2.bias',\n",
    "    'fc3.weight',\n",
    "    'fc3.bias'\n",
    "] # Modeldeki tüm parametre isimlerini listele\n",
    "new_model = Network()\n",
    "load_model_from_csr(new_model, \"pruned_model_csr\", param_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

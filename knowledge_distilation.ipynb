{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c65349-e7f2-4875-9b17-d1c5cb77b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e238b3ae-ac4f-4317-8b02-003f097750e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Data Transformer\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,),(0.5,))])\n",
    "\n",
    "# 2 Create Train Dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train =True,\n",
    "                                    download = True, transform = transform)\n",
    "trainloader = DataLoader(trainset, batch_size =64, shuffle =True)\n",
    "\n",
    "#3 Create Test Dataset\n",
    "testset = torchvision.datasets.MNIST(root = \"./data\", train = False,\n",
    "                                     download = True, transform = transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d47829b-a21c-4611-8abe-f7988baf0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80aae873-643f-4f74-b11f-4112503767c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TeacherNet,self).__init__()\n",
    "        self.conv = nn.Conv2d(1,32,5)\n",
    "        self.pool = nn.MaxPool2d(5,5)\n",
    "        self.fc1 = nn.Linear(32*4*4, 128)\n",
    "        self.fc2 = nn.Linear(128,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv(x)))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5fa4623-da31-41ca-93d9-a9b0e61ecea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "teacher_model = TeacherNet().to(device)\n",
    "\n",
    "# Define Optimizer\n",
    "teacher_optimizer = optim.Adam(teacher_model.parameters(),\n",
    "                              lr = 0.001)\n",
    "\n",
    "# Define loss function\n",
    "teacher_criterion  = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9068e08-15d2-4848-ac6d-411d577da3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2257, Accuracy: 0.9367\n",
      "Epoch 2, Loss: 0.0764, Accuracy: 0.9769\n",
      "Epoch 3, Loss: 0.0585, Accuracy: 0.9821\n",
      "Epoch 4, Loss: 0.0475, Accuracy: 0.9851\n",
      "Epoch 5, Loss: 0.0416, Accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    epoch_loss =0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    #set to train mode\n",
    "    teacher_model.train()\n",
    "\n",
    "    #train for all batches of data\n",
    "    for data in trainloader:\n",
    "        X, y = data\n",
    "        X , y = X.to(device), y.to(device)\n",
    "        y_pred = teacher_model(X)\n",
    "        loss = teacher_criterion(y_pred,y)\n",
    "        loss.backward()\n",
    "        teacher_optimizer.step()\n",
    "        teacher_optimizer.zero_grad()\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        #Calculate accuracy\n",
    "        _, predicted = torch.max(y_pred,1)\n",
    "        correct_predictions += (predicted ==y).sum().item()\n",
    "        total_predictions += y.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    average_loss = epoch_loss / len(trainloader)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4c4d3de3-51a8-4276-98e4-71ad939d4be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(StudentNet,self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28,256)\n",
    "        self.fc2 = nn.Linear(256,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b2adc382-5bad-45ec-943c-67e8d4de2bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge distilation loss (KL divergence):\n",
    "def KL_loss(student_logits, teacher_logits,temperature = 1):\n",
    "    # convert teacher model output to probabilities\n",
    "    p_teacher = F.softmax(teacher_logits / temperature, dim= 1).to(device)\n",
    "\n",
    "    # convert student model output to probabilities\n",
    "    p_student  = F.softmax(student_logits / temperature, dim = 1).to(device)\n",
    "\n",
    "    #compute KL divergence loss (PyTorch's method)\n",
    "    loss = F.kl_div(p_student, p_teacher, reduction=\"batchmean\").to(device)\n",
    "\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1e95c9a1-a4fb-45a8-a30f-5dddc60e8061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3125"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5)*(1/16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "961abecb-9486-4037-8e0c-b390e7aaebe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1052)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.tensor(0.4 / 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7cec9055-9181-47ae-b185-211cc3ac1f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1104, Accuracy: 0.8946\n",
      "Epoch 2, Loss: 0.0369, Accuracy: 0.9498\n",
      "Epoch 3, Loss: 0.0176, Accuracy: 0.9633\n",
      "Epoch 4, Loss: 0.0077, Accuracy: 0.9701\n",
      "Epoch 5, Loss: 0.0024, Accuracy: 0.9738\n",
      "Epoch 6, Loss: -0.0024, Accuracy: 0.9771\n",
      "Epoch 7, Loss: -0.0058, Accuracy: 0.9799\n",
      "Epoch 8, Loss: -0.0087, Accuracy: 0.9816\n",
      "Epoch 9, Loss: -0.0114, Accuracy: 0.9836\n",
      "Epoch 10, Loss: -0.0132, Accuracy: 0.9848\n"
     ]
    }
   ],
   "source": [
    "# Innitialize Model\n",
    "student_model = StudentNet().to(device)\n",
    "\n",
    "#Define Optimizer\n",
    "student_optimizer = optim.Adam(student_model.parameters(), lr =0.001)\n",
    "student_criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "a = 0.6\n",
    "tempature = 6\n",
    "\n",
    "for epoch in range(10):\n",
    "    # set to train mode\n",
    "    student_model.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    student_model.train()\n",
    "    #train for all batches of data\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data[0].to(device),data[1].to(device)\n",
    "        student_optimizer.zero_grad()\n",
    "\n",
    "        # get student outputs\n",
    "        student_logits = student_model(inputs)\n",
    "\n",
    "        #get teacher outputs and detach them\n",
    "        #to avoid backpropagation\n",
    "        teacher_logits = teacher_model(inputs).detach()\n",
    "\n",
    "        #compute KL Divergence loss \n",
    "        loss_distill = KL_loss(student_logits, teacher_logits,temperature=tempature) \n",
    "        loss_criterion = student_criterion(student_logits,labels)\n",
    "        \n",
    "        loss = a * (1/(tempature**2))* loss_distill + (1-a)* loss_criterion\n",
    "        #run backpropagation step\n",
    "        loss.backward()\n",
    "        student_optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        #Calculate accuracy\n",
    "        _, predicted = torch.max(student_logits,1)\n",
    "        correct_predictions += (predicted ==labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    average_loss = epoch_loss / len(trainloader)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8eeb04b2-f513-4396-8314-d45f63d6135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3427, Accuracy: 0.8975\n",
      "Epoch 2, Loss: 0.1604, Accuracy: 0.9535\n",
      "Epoch 3, Loss: 0.1162, Accuracy: 0.9648\n",
      "Epoch 4, Loss: 0.0950, Accuracy: 0.9708\n",
      "Epoch 5, Loss: 0.0789, Accuracy: 0.9757\n",
      "Epoch 6, Loss: 0.0698, Accuracy: 0.9776\n",
      "Epoch 7, Loss: 0.0607, Accuracy: 0.9809\n",
      "Epoch 8, Loss: 0.0568, Accuracy: 0.9819\n",
      "Epoch 9, Loss: 0.0505, Accuracy: 0.9834\n",
      "Epoch 10, Loss: 0.0460, Accuracy: 0.9843\n"
     ]
    }
   ],
   "source": [
    "student = StudentNet().to(device)\n",
    "optimizer = optim.Adam(student.parameters(), lr =0.001)\n",
    "criterion  = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_loss =0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    #set to train mode\n",
    "    student.train()\n",
    "\n",
    "    #train for all batches of data\n",
    "    for data in trainloader:\n",
    "        X, y = data\n",
    "        X , y = X.to(device), y.to(device)\n",
    "        y_pred = student(X)\n",
    "        loss = criterion(y_pred,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        #Calculate accuracy\n",
    "        _, predicted = torch.max(y_pred,1)\n",
    "        correct_predictions += (predicted ==y).sum().item()\n",
    "        total_predictions += y.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    average_loss = epoch_loss / len(trainloader)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f10be-0cb6-4458-b653-dc63ca3f5d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
